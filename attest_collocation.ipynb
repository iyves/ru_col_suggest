{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attest_collocation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP77X5EkVbBroQAsH9zzTJk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyves/ru_col_suggest/blob/master/attest_collocation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86TaxImZ_nLv"
      },
      "source": [
        "This colab shows how to lemmatize and get replacements for collocations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdJuUWRQtZz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a14132a-a310-4d62-d640-8f07345adeaa"
      },
      "source": [
        "# Initialize the colab - clone the github repository & install the dependencies\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t0-cWbyWZoh",
        "outputId": "ab5ee06b-e2a3-415b-ba8e-d7a7f1b865dd"
      },
      "source": [
        "# Note: This file path may require modification to work with the active account's gdrive file structure\n",
        "%cd drive/MyDrive/\n",
        "! git clone https://github.com/iyves/ru_col_suggest.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "fatal: destination path 'ru_col_suggest' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jh5deU-Wf7-",
        "outputId": "e52175bf-b7aa-4eb2-e785-bedf7d738fe1"
      },
      "source": [
        "%cd /content/drive/MyDrive/ru_col_suggest/src/models\n",
        "\n",
        "# Downloading the tokenization models\n",
        "!pip install ufal.udpipe\n",
        "!pip install treetaggerwrapper\n",
        "\n",
        "# Note: Make sure to update the version to the latest (see https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/)\n",
        "!wget https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.4.tar.gz\n",
        "!wget https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
        "!wget https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
        "!wget http://corpus.leeds.ac.uk/mocky/russian.par.gz\n",
        "!sh install-tagger.sh\n",
        "!wget http://corpus.leeds.ac.uk/mocky/ru-table.tab\n",
        "\n",
        "# Installation for windows: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/#Windows\n",
        "# Move the bin, lib, and cmd folders to the src/models folder"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ru_col_suggest/src/models\n",
            "Requirement already satisfied: ufal.udpipe in /usr/local/lib/python3.7/dist-packages (1.2.0.3)\n",
            "Requirement already satisfied: treetaggerwrapper in /usr/local/lib/python3.7/dist-packages (2.3)\n",
            "--2021-07-25 06:35:57--  https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.4.tar.gz\n",
            "Resolving www.cis.lmu.de (www.cis.lmu.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.lmu.de (www.cis.lmu.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1889240 (1.8M) [application/x-gzip]\n",
            "Saving to: ‘tree-tagger-linux-3.2.4.tar.gz.4’\n",
            "\n",
            "tree-tagger-linux-3 100%[===================>]   1.80M  2.37MB/s    in 0.8s    \n",
            "\n",
            "2021-07-25 06:35:58 (2.37 MB/s) - ‘tree-tagger-linux-3.2.4.tar.gz.4’ saved [1889240/1889240]\n",
            "\n",
            "--2021-07-25 06:35:58--  https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
            "Resolving www.cis.lmu.de (www.cis.lmu.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.lmu.de (www.cis.lmu.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 107396 (105K) [application/x-gzip]\n",
            "Saving to: ‘tagger-scripts.tar.gz.4’\n",
            "\n",
            "tagger-scripts.tar. 100%[===================>] 104.88K   325KB/s    in 0.3s    \n",
            "\n",
            "2021-07-25 06:35:59 (325 KB/s) - ‘tagger-scripts.tar.gz.4’ saved [107396/107396]\n",
            "\n",
            "--2021-07-25 06:35:59--  https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
            "Resolving www.cis.lmu.de (www.cis.lmu.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.lmu.de (www.cis.lmu.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14315 (14K) [application/x-shellscript]\n",
            "Saving to: ‘install-tagger.sh.4’\n",
            "\n",
            "install-tagger.sh.4 100%[===================>]  13.98K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-07-25 06:35:59 (131 KB/s) - ‘install-tagger.sh.4’ saved [14315/14315]\n",
            "\n",
            "--2021-07-25 06:35:59--  http://corpus.leeds.ac.uk/mocky/russian.par.gz\n",
            "Resolving corpus.leeds.ac.uk (corpus.leeds.ac.uk)... 129.11.80.147\n",
            "Connecting to corpus.leeds.ac.uk (corpus.leeds.ac.uk)|129.11.80.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7616366 (7.3M) [application/x-gzip]\n",
            "Saving to: ‘russian.par.gz.4’\n",
            "\n",
            "russian.par.gz.4    100%[===================>]   7.26M  2.55MB/s    in 2.8s    \n",
            "\n",
            "2021-07-25 06:36:03 (2.55 MB/s) - ‘russian.par.gz.4’ saved [7616366/7616366]\n",
            "\n",
            "mkdir: cannot create directory ‘cmd’: File exists\n",
            "mkdir: cannot create directory ‘lib’: File exists\n",
            "mkdir: cannot create directory ‘bin’: File exists\n",
            "mkdir: cannot create directory ‘doc’: File exists\n",
            "\n",
            "TreeTagger version for PC-Linux installed.\n",
            "Tagging scripts installed.\n",
            "Russian parameter file installed.\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "Path variables modified in tagging scripts.\n",
            "\n",
            "You might want to add /content/drive/My Drive/ru_col_suggest/src/models/cmd and /content/drive/My Drive/ru_col_suggest/src/models/bin to the PATH variable so that you do not need to specify the full path to run the tagging scripts.\n",
            "\n",
            "--2021-07-25 06:36:06--  http://corpus.leeds.ac.uk/mocky/ru-table.tab\n",
            "Resolving corpus.leeds.ac.uk (corpus.leeds.ac.uk)... 129.11.80.147\n",
            "Connecting to corpus.leeds.ac.uk (corpus.leeds.ac.uk)|129.11.80.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52704 (51K) [text/plain]\n",
            "Saving to: ‘ru-table.tab.4’\n",
            "\n",
            "ru-table.tab.4      100%[===================>]  51.47K   277KB/s    in 0.2s    \n",
            "\n",
            "2021-07-25 06:36:06 (277 KB/s) - ‘ru-table.tab.4’ saved [52704/52704]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVXphKP2YeCy",
        "outputId": "c447f7c4-e890-42ef-d696-7f9dff202702"
      },
      "source": [
        "# If the github is already cloned, only this cell must be run after restarting the runtime\n",
        "# Note: be sure to mount the gdrive before continuing\n",
        "%cd /content/drive/MyDrive/ru_col_suggest/\n",
        "!git fetch\n",
        "!git pull\n",
        "# !git reset --hard origin/master\n",
        "\n",
        "!pip install wget\n",
        "\n",
        "# For static word embedding models\n",
        "!pip install glove-python-binary\n",
        "!pip install gensim\n",
        "\n",
        "# For dynamic word embedding models\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'\n",
        "\n",
        "# For attesting collocations\n",
        "!pip install mysql-connector-python\n",
        "\n",
        "# Note: be sure to update the config.ini file and restart the runtime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ru_col_suggest\n",
            "Already up to date.\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n",
            "Requirement already satisfied: glove-python-binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-xft9d1rr\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-xft9d1rr\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (0.0.45)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (5.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (0.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.6.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.10.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.10.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0.dev0) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (7.1.2)\n",
            "tokenizers                    0.10.3\n",
            "transformers                  4.10.0.dev0\n",
            "Requirement already satisfied: mysql-connector-python in /usr/local/lib/python3.7/dist-packages (8.0.26)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from mysql-connector-python) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.0.0->mysql-connector-python) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeiKdgu8Aer4"
      },
      "source": [
        "## Lemmatization of collocations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34101f2oWqF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f93b14-57b6-463a-f628-86041dc9b763"
      },
      "source": [
        "from src.tokenizer import Tokenizer\n",
        "\n",
        "input_collocations = [\"исследуем вопрос\", \"по мнению авторов\"]\n",
        "\n",
        "# Lemmatization via UDPipe\n",
        "print(\"\\n\"*2, \"Lemmatization via UDPipe\")\n",
        "tokenizer = Tokenizer(Tokenizer.Method.UDPIPE)\n",
        "udpipe_output = tokenizer.tokenize(input_collocations)\n",
        "for inp, outp in zip(input_collocations, udpipe_output):\n",
        "  print(inp, \"->\", outp)\n",
        "\n",
        "\n",
        "# Lemmatization via TreeTagger\n",
        "print(\"\\n\"*2, \"Lemmatization via TreeTagger\")\n",
        "tokenizer = Tokenizer(Tokenizer.Method.TREETAGGER)\n",
        "treetagger_output = tokenizer.tokenize(input_collocations)\n",
        "for inp, outp in zip(input_collocations, treetagger_output):\n",
        "  print(inp, \"->\", outp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:740: FutureWarning: Possible nested set at position 8\n",
            "  re.IGNORECASE | re.VERBOSE)\n",
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:2044: FutureWarning: Possible nested set at position 152\n",
            "  re.VERBOSE | re.IGNORECASE)\n",
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:2067: FutureWarning: Possible nested set at position 409\n",
            "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:2079: FutureWarning: Possible nested set at position 192\n",
            "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
            "\n",
            "Loading the model from /content/drive/MyDrive/ru_col_suggest/src/models/udpipe_syntagrus.model...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Lemmatization via UDPipe\n",
            "исследуем вопрос -> исследовать_VERB вопрос_NOUN\n",
            "по мнению авторов -> по_ADP мнение_NOUN автор_NOUN\n",
            "\n",
            "\n",
            " Lemmatization via TreeTagger\n",
            "исследуем вопрос -> исследовать_V вопрос_N\n",
            "по мнению авторов -> по_S мнение_N автор_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYuuIVCCIt5x"
      },
      "source": [
        "## Getting suggested collocations from static word embeddings (w2v, fastText, GloVe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9NLo-giIqnp"
      },
      "source": [
        "from src.static_embedder import LossLogger, StaticEmbedder\n",
        "\n",
        "w2v_path = \"/content/drive/MyDrive/models/lemma/w2v/w2v_treetagger.model\"\n",
        "fasttext_path = \"/content/drive/MyDrive/models/lemma/fastText/fastText_treetagger.model\"\n",
        "glove_path = \"/content/drive/MyDrive/models/lemma/glove/glove_treetagger.txt.word2vec\"\n",
        "\n",
        "# Load static word embedding models pretrained on a treetagger-lemmatized corpus\n",
        "w2v_model = StaticEmbedder(StaticEmbedder.Model.WORD2VEC, w2v_path)\n",
        "fasttext_model = StaticEmbedder(StaticEmbedder.Model.FASTTEXT, fasttext_path)\n",
        "glove_model = StaticEmbedder(StaticEmbedder.Model.GLOVE, glove_path, binary=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHOBRz1CkHXi",
        "outputId": "5583ef33-2401-4b4f-cb22-72909468fcf5"
      },
      "source": [
        "# Get some suggested collocations\n",
        "treetagger_output = [\"исследовать_V вопрос_N\", \"по_S мнение_N автор_N\"]\n",
        "\n",
        "for ngram, fixed_positions in zip(treetagger_output, [[1, 0], [1, 1, 0]]):\n",
        "  query = ngram.lower().split(\" \")\n",
        "  \n",
        "  w2v_results = w2v_model.suggest_collocations(query, fixed_positions, topn=5)\n",
        "  fasttext_results = fasttext_model.suggest_collocations(query, fixed_positions, topn=5)\n",
        "  glove_results = glove_model.suggest_collocations(query, fixed_positions, topn=25)\n",
        "  \n",
        "  print(\"Results for\", query, \":\")\n",
        "  print(\"_____w2v_____\")\n",
        "  for res in w2v_results:\n",
        "    print(res)\n",
        "  print(\"\\n_____fastText_____\")\n",
        "  for res in fasttext_results:\n",
        "    print(res)\n",
        "  print(\"\\n_____GloVe_____\")\n",
        "  for res in glove_results:\n",
        "    print(res)\n",
        "  print(\"-\"*75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for ['исследовать_v', 'вопрос_n'] :\n",
            "_____w2v_____\n",
            "('исследовать проблема', 0, 0.6838977336883545)\n",
            "('исследовать задача', 1, 0.48253941535949707)\n",
            "('исследовать спор', 2, 0.459981232881546)\n",
            "('исследовать вопрсы', 3, 0.44508951902389526)\n",
            "\n",
            "_____fastText_____\n",
            "('исследовать новопрос', 0, 0.8441401720046997)\n",
            "('исследовать вопроа', 3, 0.800765872001648)\n",
            "\n",
            "_____GloVe_____\n",
            "('исследовать итервьюера', 23, 0.5414384603500366)\n",
            "---------------------------------------------------------------------------\n",
            "Results for ['по_s', 'мнение_n', 'автор_n'] :\n",
            "_____w2v_____\n",
            "('по мнение исследователь', 0, 0.6782662272453308)\n",
            "('по мнение ученый', 2, 0.5683425664901733)\n",
            "('по мнение историк', 3, 0.443101167678833)\n",
            "\n",
            "_____fastText_____\n",
            "('по мнение исследователь', 0, 0.6990058422088623)\n",
            "('по мнение втор', 1, 0.6199074387550354)\n",
            "('по мнение ученый', 2, 0.6077357530593872)\n",
            "('по мнение пвтор', 3, 0.5964410305023193)\n",
            "\n",
            "_____GloVe_____\n",
            "('по мнение помпонио', 1, 0.7873562574386597)\n",
            "('по мнение ряженки', 2, 0.7458928227424622)\n",
            "('по мнение рсунков', 3, 0.7190617322921753)\n",
            "('по мнение экпозиций', 5, 0.6796302795410156)\n",
            "('по мнение кастаниаса', 6, 0.6711572408676147)\n",
            "('по мнение сеника', 7, 0.6687108874320984)\n",
            "('по мнение йоханом', 8, 0.660228967666626)\n",
            "('по мнение липсиц', 9, 0.6584478616714478)\n",
            "('по мнение утопизму', 14, 0.6325863003730774)\n",
            "('по мнение мытарствами', 17, 0.6175637245178223)\n",
            "('по мнение совастеевым', 18, 0.6129472255706787)\n",
            "('по мнение стихтворения', 19, 0.6094455718994141)\n",
            "('по мнение рчепорождения', 24, 0.5966158509254456)\n",
            "---------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8lkE1xKnNpg"
      },
      "source": [
        "## Getting suggested collocations from dynamic word embeddings (RoBERTa, t5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PZQDrtSnaT7"
      },
      "source": [
        "from src.dynamic_embedder import DynamicEmbedder\n",
        "\n",
        "bert_path = \"/content/drive/MyDrive/models/lemma/RuBERT_treetagger_lemma\"\n",
        "\n",
        "# Load a dynamic word embedding model trained on a treetagger-lemmatized corpus\n",
        "bert_model = DynamicEmbedder(DynamicEmbedder.Model.BERT, bert_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "277ylLfXnmjx",
        "outputId": "2d585ca6-337f-4f57-bec9-ac5dc1cb777e"
      },
      "source": [
        "# Get some suggested collocations\n",
        "treetagger_output = [\"исследовать_V <mask>_N\", \n",
        "                     \"по_S мнение_N <mask>_N\", \n",
        "                     \"рассматривать_V <mask>_N <mask>_N\"]\n",
        "\n",
        "for ngram in treetagger_output:\n",
        "  query = ngram.lower()\n",
        "  bert_results = bert_model.suggest_collocations(query, topn=5)\n",
        "  \n",
        "  print(\"Results for\", query, \":\")\n",
        "  print(\"_____RoBERTa_____\")\n",
        "  for res in bert_results:\n",
        "    print(res)\n",
        "  print(\"-\"*75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for исследовать_v <mask>_n :\n",
            "_____RoBERTa_____\n",
            "('исследовать конституция', 0)\n",
            "('исследовать законодательство', 1)\n",
            "('исследовать автореферат', 2)\n",
            "('исследовать диссертация', 3)\n",
            "('исследовать закон', 4)\n",
            "---------------------------------------------------------------------------\n",
            "Results for по_s мнение_n <mask>_n :\n",
            "_____RoBERTa_____\n",
            "('по мнение NUMarab', 0)\n",
            "('по мнение автор', 1)\n",
            "('по мнение ученый', 2)\n",
            "('по мнение эксперт', 3)\n",
            "('по мнение судья', 4)\n",
            "---------------------------------------------------------------------------\n",
            "Results for рассматривать_v <mask>_n <mask>_n :\n",
            "_____RoBERTa_____\n",
            "('рассматривать международный NUMarab', 0)\n",
            "('рассматривать международный монография', 1)\n",
            "('рассматривать международный проблема', 2)\n",
            "('рассматривать международный суд', 3)\n",
            "('рассматривать международный целесообразный', 4)\n",
            "('рассматривать содержание NUMarab', 1)\n",
            "('рассматривать содержание монография', 2)\n",
            "('рассматривать содержание проблема', 3)\n",
            "('рассматривать содержание суд', 4)\n",
            "('рассматривать содержание целесообразный', 5)\n",
            "('рассматривать проблема NUMarab', 2)\n",
            "('рассматривать проблема монография', 3)\n",
            "('рассматривать проблема проблема', 4)\n",
            "('рассматривать проблема суд', 5)\n",
            "('рассматривать проблема целесообразный', 6)\n",
            "('рассматривать этот NUMarab', 3)\n",
            "('рассматривать этот монография', 4)\n",
            "('рассматривать этот проблема', 5)\n",
            "('рассматривать этот суд', 6)\n",
            "('рассматривать этот целесообразный', 7)\n",
            "('рассматривать российский NUMarab', 4)\n",
            "('рассматривать российский монография', 5)\n",
            "('рассматривать российский проблема', 6)\n",
            "('рассматривать российский суд', 7)\n",
            "('рассматривать российский целесообразный', 8)\n",
            "---------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEkj05ksVTK_"
      },
      "source": [
        "## Getting suggested collocations & statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLWynpvsAl0G"
      },
      "source": [
        "# Run this and allow the IP on the test gcloud server \n",
        "!curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC_1VYEvVScL"
      },
      "source": [
        "from src.get_collocation_replacements import getCollocationReplacements\n",
        "from src.dynamic_embedder import DynamicEmbedder\n",
        "from src.static_embedder import LossLogger, StaticEmbedder\n",
        "\n",
        "bigrams = [l.lower() for l in [\"исследовать_V вопрос_N\", \"школа_N экономика_N\"]]\n",
        "trigrams = [l.lower() for l in [\"прийти_V к_S вывод_N\", \"по_S мнение_N автор_N\"]]\n",
        "\n",
        "w2v_path = \"/content/drive/MyDrive/models/lemma/w2v/w2v_treetagger.model\"\n",
        "bert_path = \"/content/drive/MyDrive/models/lemma/RuBERT_treetagger_lemma\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZeIa1_MOIew"
      },
      "source": [
        "bigram_results = getCollocationReplacements(collocations=bigrams, \n",
        "                                            staticModel=True, \n",
        "                                            modelType=StaticEmbedder.Model.WORD2VEC,\n",
        "                                            modelSrc=w2v_path, \n",
        "                                            binaryModel=True, # only relevant for GloVe\n",
        "                                            cossim=True,\n",
        "                                            topn=3,\n",
        "                                            replace1=True, replace2=True, replace3=False,\n",
        "                                            include_pmi=True, include_t_score=True, include_ngram_freq=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S903k8keGRTk"
      },
      "source": [
        "trigram_results = getCollocationReplacements(collocations=trigrams, \n",
        "                                             staticModel=False, \n",
        "                                             modelType=DynamicEmbedder.Model.BERT,\n",
        "                                             modelSrc=bert_path,\n",
        "                                             mask=\"<mask>\",\n",
        "                                             topn=3,\n",
        "                                             replace1=True, replace2=True, replace3=True,\n",
        "                                             include_pmi=True, include_t_score=True, include_ngram_freq=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRKFCVKXOXqz",
        "outputId": "6fe295a2-2be4-4ca1-d447-f948144e1735"
      },
      "source": [
        "def print_results(res):\n",
        "  for k,v in res.items():\n",
        "    print(f\"Results for '{k}':\")\n",
        "    for val in v:\n",
        "      print(\" \"*5, val)\n",
        "    print(\"-\"*75)\n",
        "\n",
        "print(\"*\"*5, \"BIGRAMS WITH W2V\", \"*\"*5)\n",
        "print_results(bigram_results)\n",
        "print(\"\\n\")\n",
        "print(\"*\"*5, \"TRIGRAMS WITH BERT\", \"*\"*5)\n",
        "print_results(trigram_results)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** BIGRAMS WITH W2V *****\n",
            "Results for 'исследовать_v вопрос_n':\n",
            "      {'suggested': 'анализировать вопрос', 'rank': 0, 'cosScore': 0.5687171816825867, 'numReplaced': 1, 'pmi': -1.9326116004215073, 't_score': -713.0812254264505, 'ngram_freq': 71}\n",
            "      {'suggested': 'рассматривать вопрос', 'rank': 1, 'cosScore': 0.5575243234634399, 'numReplaced': 1, 'pmi': -0.8382014019729593, 't_score': -322.48555306741184, 'ngram_freq': 2998}\n",
            "      {'suggested': 'изучить вопрос', 'rank': 2, 'cosScore': 0.553035318851471, 'numReplaced': 1, 'pmi': -1.5870879940255196, 't_score': -255.31760297908693, 'ngram_freq': 46}\n",
            "      {'suggested': 'исследовать проблема', 'rank': 0, 'cosScore': 0.6838977336883545, 'numReplaced': 1, 'pmi': -0.722491713486314, 't_score': -132.48833138166378, 'ngram_freq': 959}\n",
            "      {'suggested': 'анализировать вопрос', 'rank': 0, 'cosScore': 0.5687171816825867, 'numReplaced': 2, 'pmi': -1.9326116004215073, 't_score': -713.0812254264505, 'ngram_freq': 71}\n",
            "      {'suggested': 'рассматривать вопрос', 'rank': 1, 'cosScore': 0.5575243234634399, 'numReplaced': 2, 'pmi': -0.8382014019729593, 't_score': -322.48555306741184, 'ngram_freq': 2998}\n",
            "      {'suggested': 'изучить вопрос', 'rank': 2, 'cosScore': 0.553035318851471, 'numReplaced': 2, 'pmi': -1.5870879940255196, 't_score': -255.31760297908693, 'ngram_freq': 46}\n",
            "      {'suggested': 'исследовать проблема', 'rank': 0, 'cosScore': 0.6838977336883545, 'numReplaced': 2, 'pmi': -0.722491713486314, 't_score': -132.48833138166378, 'ngram_freq': 959}\n",
            "---------------------------------------------------------------------------\n",
            "Results for 'школа_n экономика_n':\n",
            "      {'suggested': 'учитель экономика', 'rank': 1, 'cosScore': 0.4992271065711975, 'numReplaced': 1, 'pmi': -1.9473737666819497, 't_score': -689.6667862412795, 'ngram_freq': 62}\n",
            "      {'suggested': 'учитель экономика', 'rank': 1, 'cosScore': 0.4992271065711975, 'numReplaced': 2, 'pmi': -1.9473737666819497, 't_score': -689.6667862412795, 'ngram_freq': 62}\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "***** TRIGRAMS WITH BERT *****\n",
            "Results for 'прийти_v к_s вывод_n':\n",
            "      {'suggested': 'прийти к вывод', 'rank': 0, 'numReplaced': 1, 'pmi': 0.6351189488335738, 't_score': 34.71940443123701, 'ngram_freq': 2042}\n",
            "      {'suggested': 'прийти к власть', 'rank': 2, 'numReplaced': 1, 'pmi': -1.6443524703588472, 't_score': -243.7609545514276, 'ngram_freq': 32}\n",
            "      {'suggested': 'прийти к вывод', 'rank': 0, 'numReplaced': 2, 'pmi': 0.6351189488335738, 't_score': 34.71940443123701, 'ngram_freq': 2042}\n",
            "      {'suggested': 'прийти к власть', 'rank': 2, 'numReplaced': 2, 'pmi': -1.6443524703588472, 't_score': -243.7609545514276, 'ngram_freq': 32}\n",
            "      {'suggested': 'прийти к вывод', 'rank': 0, 'numReplaced': 3, 'pmi': 0.6351189488335738, 't_score': 34.71940443123701, 'ngram_freq': 2042}\n",
            "      {'suggested': 'прийти к власть', 'rank': 2, 'numReplaced': 3, 'pmi': -1.6443524703588472, 't_score': -243.7609545514276, 'ngram_freq': 32}\n",
            "---------------------------------------------------------------------------\n",
            "Results for 'по_s мнение_n автор_n':\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 1, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 1, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по слово автор', 'rank': 2, 'numReplaced': 1, 'pmi': -0.8751056781889914, 't_score': -56.67237330170388, 'ngram_freq': 76}\n",
            "      {'suggested': 'по мнение автор', 'rank': 1, 'numReplaced': 1, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение ученый', 'rank': 2, 'numReplaced': 1, 'pmi': -0.6199384934559808, 't_score': -70.20048391336107, 'ngram_freq': 491}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 2, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 2, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по слово автор', 'rank': 2, 'numReplaced': 2, 'pmi': -0.8751056781889914, 't_score': -56.67237330170388, 'ngram_freq': 76}\n",
            "      {'suggested': 'по мнение автор', 'rank': 1, 'numReplaced': 2, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение ученый', 'rank': 2, 'numReplaced': 2, 'pmi': -0.6199384934559808, 't_score': -70.20048391336107, 'ngram_freq': 491}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 3, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 3, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по слово автор', 'rank': 2, 'numReplaced': 3, 'pmi': -0.8751056781889914, 't_score': -56.67237330170388, 'ngram_freq': 76}\n",
            "      {'suggested': 'по мнение автор', 'rank': 1, 'numReplaced': 3, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение ученый', 'rank': 2, 'numReplaced': 3, 'pmi': -0.6199384934559808, 't_score': -70.20048391336107, 'ngram_freq': 491}\n",
            "---------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkeqAi7srxCQ"
      },
      "source": [
        "## Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx33G8uxsXdk"
      },
      "source": [
        "# Run this and allow the IP on the test gcloud server \n",
        "!curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkMQaENMrwTD",
        "outputId": "89fd9357-2a59-48a4-bcbf-d845fb7f9f94"
      },
      "source": [
        "from src.get_collocation_replacements import getCollocationReplacements\n",
        "from src.dynamic_embedder import DynamicEmbedder\n",
        "from src.tokenizer import Tokenizer\n",
        "\n",
        "input_collocations = [\"как мы полагаем\", \"по мнению авторов\", \"экономическое развитие страны\"]\n",
        "bert_path = \"/content/drive/MyDrive/models/lemma/RuBERT_treetagger_lemma\"\n",
        "\n",
        "tokenizer = Tokenizer(Tokenizer.Method.TREETAGGER)\n",
        "lemmas = [l.lower() for l in tokenizer.tokenize(input_collocations)]\n",
        "res = getCollocationReplacements(collocations=lemmas, \n",
        "                                 staticModel=False, \n",
        "                                 modelType=DynamicEmbedder.Model.BERT,\n",
        "                                 modelSrc=bert_path,\n",
        "                                 mask=\"<mask>\",\n",
        "                                 topn=3,\n",
        "                                 replace1=True, replace2=True, replace3=False,\n",
        "                                 include_pmi=True, include_t_score=True, include_ngram_freq=True)\n",
        "for k,v in res.items():\n",
        "    print(f\"Results for '{k}':\")\n",
        "    for val in v:\n",
        "      print(\" \"*5, val)\n",
        "    print(\"-\"*75)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:740: FutureWarning: Possible nested set at position 8\n",
            "  re.IGNORECASE | re.VERBOSE)\n",
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:2044: FutureWarning: Possible nested set at position 152\n",
            "  re.VERBOSE | re.IGNORECASE)\n",
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:2067: FutureWarning: Possible nested set at position 409\n",
            "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:2079: FutureWarning: Possible nested set at position 192\n",
            "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results for 'как_c мы_p полагать_v':\n",
            "      {'suggested': 'как мы полагать', 'rank': 0, 'numReplaced': 1, 'pmi': -0.15771885657613424, 't_score': -4.7159769128401825, 'ngram_freq': 116}\n",
            "      {'suggested': 'поэтому мы полагать', 'rank': 2, 'numReplaced': 1, 'pmi': -0.2828475279561056, 't_score': -4.001448538290557, 'ngram_freq': 19}\n",
            "      {'suggested': 'как мы полагать', 'rank': 0, 'numReplaced': 1, 'pmi': -0.15771885657613424, 't_score': -4.7159769128401825, 'ngram_freq': 116}\n",
            "      {'suggested': 'как он полагать', 'rank': 2, 'numReplaced': 1, 'pmi': -0.7479600608679128, 't_score': -21.066381231921344, 'ngram_freq': 21}\n",
            "      {'suggested': 'как мы представляться', 'rank': 0, 'numReplaced': 1, 'pmi': 0.32084496077632957, 't_score': 11.502469224085171, 'ngram_freq': 485}\n",
            "      {'suggested': 'как мы отмечать', 'rank': 1, 'numReplaced': 1, 'pmi': -0.7348097952799268, 't_score': -40.116484488604144, 'ngram_freq': 82}\n",
            "      {'suggested': 'как мы видеть', 'rank': 2, 'numReplaced': 1, 'pmi': 0.3331095806207803, 't_score': 14.04870654763227, 'ngram_freq': 688}\n",
            "      {'suggested': 'как мы полагать', 'rank': 0, 'numReplaced': 2, 'pmi': -0.15771885657613424, 't_score': -4.7159769128401825, 'ngram_freq': 116}\n",
            "      {'suggested': 'поэтому мы полагать', 'rank': 2, 'numReplaced': 2, 'pmi': -0.2828475279561056, 't_score': -4.001448538290557, 'ngram_freq': 19}\n",
            "      {'suggested': 'как мы полагать', 'rank': 0, 'numReplaced': 2, 'pmi': -0.15771885657613424, 't_score': -4.7159769128401825, 'ngram_freq': 116}\n",
            "      {'suggested': 'как он полагать', 'rank': 2, 'numReplaced': 2, 'pmi': -0.7479600608679128, 't_score': -21.066381231921344, 'ngram_freq': 21}\n",
            "      {'suggested': 'как мы представляться', 'rank': 0, 'numReplaced': 2, 'pmi': 0.32084496077632957, 't_score': 11.502469224085171, 'ngram_freq': 485}\n",
            "      {'suggested': 'как мы отмечать', 'rank': 1, 'numReplaced': 2, 'pmi': -0.7348097952799268, 't_score': -40.116484488604144, 'ngram_freq': 82}\n",
            "      {'suggested': 'как мы видеть', 'rank': 2, 'numReplaced': 2, 'pmi': 0.3331095806207803, 't_score': 14.04870654763227, 'ngram_freq': 688}\n",
            "---------------------------------------------------------------------------\n",
            "Results for 'по_s мнение_n автор_n':\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 1, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 1, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по слово автор', 'rank': 2, 'numReplaced': 1, 'pmi': -0.8751056781889914, 't_score': -56.67237330170388, 'ngram_freq': 76}\n",
            "      {'suggested': 'по мнение автор', 'rank': 1, 'numReplaced': 1, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение ученый', 'rank': 2, 'numReplaced': 1, 'pmi': -0.6199384934559808, 't_score': -70.20048391336107, 'ngram_freq': 491}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 2, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 2, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по слово автор', 'rank': 2, 'numReplaced': 2, 'pmi': -0.8751056781889914, 't_score': -56.67237330170388, 'ngram_freq': 76}\n",
            "      {'suggested': 'по мнение автор', 'rank': 1, 'numReplaced': 2, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение ученый', 'rank': 2, 'numReplaced': 2, 'pmi': -0.6199384934559808, 't_score': -70.20048391336107, 'ngram_freq': 491}\n",
            "---------------------------------------------------------------------------\n",
            "Results for 'экономический_a развитие_n страна_n':\n",
            "      {'suggested': 'экономический развитие страна', 'rank': 1, 'numReplaced': 1, 'pmi': -0.8462727909927793, 't_score': -102.67577252001053, 'ngram_freq': 291}\n",
            "      {'suggested': 'экономический развитие страна', 'rank': 0, 'numReplaced': 1, 'pmi': -0.8462727909927793, 't_score': -102.67577252001053, 'ngram_freq': 291}\n",
            "      {'suggested': 'экономический безопасность страна', 'rank': 2, 'numReplaced': 1, 'pmi': -1.4457664941797606, 't_score': -97.02692749678283, 'ngram_freq': 13}\n",
            "      {'suggested': 'экономический развитие Россия', 'rank': 1, 'numReplaced': 1, 'pmi': -1.3837397053740013, 't_score': -207.46940252268374, 'ngram_freq': 80}\n",
            "      {'suggested': 'экономический развитие страна', 'rank': 1, 'numReplaced': 2, 'pmi': -0.8462727909927793, 't_score': -102.67577252001053, 'ngram_freq': 291}\n",
            "      {'suggested': 'экономический развитие страна', 'rank': 0, 'numReplaced': 2, 'pmi': -0.8462727909927793, 't_score': -102.67577252001053, 'ngram_freq': 291}\n",
            "      {'suggested': 'экономический безопасность страна', 'rank': 2, 'numReplaced': 2, 'pmi': -1.4457664941797606, 't_score': -97.02692749678283, 'ngram_freq': 13}\n",
            "      {'suggested': 'экономический развитие Россия', 'rank': 1, 'numReplaced': 2, 'pmi': -1.3837397053740013, 't_score': -207.46940252268374, 'ngram_freq': 80}\n",
            "---------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4TsdmTwhhh2"
      },
      "source": [
        "## Save the results to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgziqkjsYZNr"
      },
      "source": [
        "from src.get_collocation_replacements import writeResults\n",
        "\n",
        "writeResults(res, save_folder=\"/content/drive/MyDrive/ru_col_suggest/data/log\")"
      ],
      "execution_count": 3,
      "outputs": []
    }
  ]
}