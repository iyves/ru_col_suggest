{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attest_collocation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQ4OiljvrS0ETUx6DDt2QT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyves/ru_col_suggest/blob/master/attest_collocation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86TaxImZ_nLv"
      },
      "source": [
        "This colab shows how to lemmatize and get replacements for collocations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdJuUWRQtZz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f812f9f1-0c05-4234-f310-08050d9f77bd"
      },
      "source": [
        "# Initialize the colab - clone the github repository & install the dependencies\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t0-cWbyWZoh",
        "outputId": "ab5ee06b-e2a3-415b-ba8e-d7a7f1b865dd"
      },
      "source": [
        "# Note: This file path may require modification to work with the active account's gdrive file structure\n",
        "%cd drive/MyDrive/\n",
        "! git clone https://github.com/iyves/ru_col_suggest.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "fatal: destination path 'ru_col_suggest' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jh5deU-Wf7-",
        "outputId": "694d49b8-ace2-4271-a7e0-d8370f483259"
      },
      "source": [
        "%cd /content/drive/MyDrive/ru_col_suggest/src/models\n",
        "\n",
        "# Downloading the tokenization models\n",
        "!pip install ufal.udpipe\n",
        "!pip install treetaggerwrapper\n",
        "\n",
        "# Note: Make sure to update the version to the latest (see https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/)\n",
        "!wget https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.4.tar.gz\n",
        "!wget https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
        "!wget https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
        "!wget http://corpus.leeds.ac.uk/mocky/russian.par.gz\n",
        "!sh install-tagger.sh\n",
        "!wget http://corpus.leeds.ac.uk/mocky/ru-table.tab\n",
        "\n",
        "# Installation for windows: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/#Windows\n",
        "# Move the bin, lib, and cmd folders to the src/models folder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ru_col_suggest/src/models\n",
            "Collecting ufal.udpipe\n",
            "  Downloading ufal.udpipe-1.2.0.3.tar.gz (304 kB)\n",
            "\u001b[K     |████████████████████████████████| 304 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ufal.udpipe\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp37-cp37m-linux_x86_64.whl size=5626696 sha256=09f4b60e20e9977840f7f00610d4fccf7253cd5355bd95d45f7e39718eb1ed5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/b5/8e/3da091629a21ce2d10bf90759d0cb034ba10a5cf7a01e83d64\n",
            "Successfully built ufal.udpipe\n",
            "Installing collected packages: ufal.udpipe\n",
            "Successfully installed ufal.udpipe-1.2.0.3\n",
            "Collecting treetaggerwrapper\n",
            "  Downloading treetaggerwrapper-2.3.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: treetaggerwrapper\n",
            "  Building wheel for treetaggerwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treetaggerwrapper: filename=treetaggerwrapper-2.3-py3-none-any.whl size=40771 sha256=67516beb9af9187ac56a7308a057040ae551858caa69f2f4a88f2b7b518bcd3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/93/50/47079639c52033b2e2b865a59654eea6832068149414cb78a5\n",
            "Successfully built treetaggerwrapper\n",
            "Installing collected packages: treetaggerwrapper\n",
            "Successfully installed treetaggerwrapper-2.3\n",
            "--2021-07-22 21:14:23--  https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.4.tar.gz\n",
            "Resolving www.cis.lmu.de (www.cis.lmu.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.lmu.de (www.cis.lmu.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1889240 (1.8M) [application/x-gzip]\n",
            "Saving to: ‘tree-tagger-linux-3.2.4.tar.gz.1’\n",
            "\n",
            "tree-tagger-linux-3 100%[===================>]   1.80M  2.38MB/s    in 0.8s    \n",
            "\n",
            "2021-07-22 21:14:24 (2.38 MB/s) - ‘tree-tagger-linux-3.2.4.tar.gz.1’ saved [1889240/1889240]\n",
            "\n",
            "--2021-07-22 21:14:24--  https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
            "Resolving www.cis.lmu.de (www.cis.lmu.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.lmu.de (www.cis.lmu.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 107396 (105K) [application/x-gzip]\n",
            "Saving to: ‘tagger-scripts.tar.gz.1’\n",
            "\n",
            "tagger-scripts.tar. 100%[===================>] 104.88K   323KB/s    in 0.3s    \n",
            "\n",
            "2021-07-22 21:14:25 (323 KB/s) - ‘tagger-scripts.tar.gz.1’ saved [107396/107396]\n",
            "\n",
            "--2021-07-22 21:14:25--  https://www.cis.lmu.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
            "Resolving www.cis.lmu.de (www.cis.lmu.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.lmu.de (www.cis.lmu.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14315 (14K) [application/x-shellscript]\n",
            "Saving to: ‘install-tagger.sh.1’\n",
            "\n",
            "install-tagger.sh.1 100%[===================>]  13.98K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-07-22 21:14:26 (130 KB/s) - ‘install-tagger.sh.1’ saved [14315/14315]\n",
            "\n",
            "--2021-07-22 21:14:26--  http://corpus.leeds.ac.uk/mocky/russian.par.gz\n",
            "Resolving corpus.leeds.ac.uk (corpus.leeds.ac.uk)... 129.11.80.147\n",
            "Connecting to corpus.leeds.ac.uk (corpus.leeds.ac.uk)|129.11.80.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7616366 (7.3M) [application/x-gzip]\n",
            "Saving to: ‘russian.par.gz.1’\n",
            "\n",
            "russian.par.gz.1    100%[===================>]   7.26M  1.98MB/s    in 3.7s    \n",
            "\n",
            "2021-07-22 21:14:30 (1.98 MB/s) - ‘russian.par.gz.1’ saved [7616366/7616366]\n",
            "\n",
            "mkdir: cannot create directory ‘cmd’: File exists\n",
            "mkdir: cannot create directory ‘lib’: File exists\n",
            "mkdir: cannot create directory ‘bin’: File exists\n",
            "mkdir: cannot create directory ‘doc’: File exists\n",
            "\n",
            "TreeTagger version for PC-Linux installed.\n",
            "Tagging scripts installed.\n",
            "Russian parameter file installed.\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "awk: line 1: runaway string constant \"BIN=\\\"/con ...\n",
            "Path variables modified in tagging scripts.\n",
            "\n",
            "You might want to add /content/drive/My Drive/ru_col_suggest/src/models/cmd and /content/drive/My Drive/ru_col_suggest/src/models/bin to the PATH variable so that you do not need to specify the full path to run the tagging scripts.\n",
            "\n",
            "--2021-07-22 21:14:34--  http://corpus.leeds.ac.uk/mocky/ru-table.tab\n",
            "Resolving corpus.leeds.ac.uk (corpus.leeds.ac.uk)... 129.11.80.147\n",
            "Connecting to corpus.leeds.ac.uk (corpus.leeds.ac.uk)|129.11.80.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52704 (51K) [text/plain]\n",
            "Saving to: ‘ru-table.tab.1’\n",
            "\n",
            "ru-table.tab.1      100%[===================>]  51.47K   267KB/s    in 0.2s    \n",
            "\n",
            "2021-07-22 21:14:34 (267 KB/s) - ‘ru-table.tab.1’ saved [52704/52704]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVXphKP2YeCy",
        "outputId": "9a81abd6-7199-41ff-a5d6-42a2a23adefe"
      },
      "source": [
        "# If the github is already cloned, only this cell must be run after restarting the runtime\n",
        "# Note: be sure to mount the gdrive before continuing\n",
        "%cd /content/drive/MyDrive/ru_col_suggest/\n",
        "!git fetch\n",
        "!git pull\n",
        "# !git reset --hard origin/master\n",
        "\n",
        "!pip install wget\n",
        "\n",
        "# For static word embedding models\n",
        "!pip install glove-python-binary\n",
        "!pip install gensim\n",
        "\n",
        "# For dynamic word embedding models\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'\n",
        "\n",
        "# For attesting collocations\n",
        "!pip install mysql-connector-python\n",
        "\n",
        "# Note: be sure to update the config.ini file and restart the runtime"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ru_col_suggest\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 6 (delta 4), reused 6 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n",
            "From https://github.com/iyves/ru_col_suggest\n",
            "   f7a04ce..0a425fc  master     -> origin/master\n",
            "Checking out files: 100% (64/64), done.\n",
            "HEAD is now at 0a425fc Fixed error with attesting and getting frequency for trigrams.\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n",
            "Requirement already satisfied: glove-python-binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-6hq20dok\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-6hq20dok\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.6.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (21.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (0.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.10.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.10.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0.dev0) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (7.1.2)\n",
            "tokenizers                    0.10.3\n",
            "transformers                  4.10.0.dev0\n",
            "Requirement already satisfied: mysql-connector-python in /usr/local/lib/python3.7/dist-packages (8.0.26)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from mysql-connector-python) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.0.0->mysql-connector-python) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeiKdgu8Aer4"
      },
      "source": [
        "## Lemmatization of collocations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34101f2oWqF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f93b14-57b6-463a-f628-86041dc9b763"
      },
      "source": [
        "from src.tokenizer import Tokenizer\n",
        "\n",
        "input_collocations = [\"исследуем вопрос\", \"по мнению авторов\"]\n",
        "\n",
        "# Lemmatization via UDPipe\n",
        "print(\"\\n\"*2, \"Lemmatization via UDPipe\")\n",
        "tokenizer = Tokenizer(Tokenizer.Method.UDPIPE)\n",
        "udpipe_output = tokenizer.tokenize(input_collocations)\n",
        "for inp, outp in zip(input_collocations, udpipe_output):\n",
        "  print(inp, \"->\", outp)\n",
        "\n",
        "\n",
        "# Lemmatization via TreeTagger\n",
        "print(\"\\n\"*2, \"Lemmatization via TreeTagger\")\n",
        "tokenizer = Tokenizer(Tokenizer.Method.TREETAGGER)\n",
        "treetagger_output = tokenizer.tokenize(input_collocations)\n",
        "for inp, outp in zip(input_collocations, treetagger_output):\n",
        "  print(inp, \"->\", outp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:740: FutureWarning: Possible nested set at position 8\n",
            "  re.IGNORECASE | re.VERBOSE)\n",
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:2044: FutureWarning: Possible nested set at position 152\n",
            "  re.VERBOSE | re.IGNORECASE)\n",
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:2067: FutureWarning: Possible nested set at position 409\n",
            "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
            "/usr/local/lib/python3.7/dist-packages/treetaggerwrapper.py:2079: FutureWarning: Possible nested set at position 192\n",
            "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
            "\n",
            "Loading the model from /content/drive/MyDrive/ru_col_suggest/src/models/udpipe_syntagrus.model...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Lemmatization via UDPipe\n",
            "исследуем вопрос -> исследовать_VERB вопрос_NOUN\n",
            "по мнению авторов -> по_ADP мнение_NOUN автор_NOUN\n",
            "\n",
            "\n",
            " Lemmatization via TreeTagger\n",
            "исследуем вопрос -> исследовать_V вопрос_N\n",
            "по мнению авторов -> по_S мнение_N автор_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYuuIVCCIt5x"
      },
      "source": [
        "## Getting suggested collocations from static word embeddings (w2v, fastText, GloVe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9NLo-giIqnp"
      },
      "source": [
        "from src.static_embedder import LossLogger, StaticEmbedder\n",
        "\n",
        "w2v_path = \"/content/drive/MyDrive/models/lemma/w2v/w2v_treetagger.model\"\n",
        "fasttext_path = \"/content/drive/MyDrive/models/lemma/fastText/fastText_treetagger.model\"\n",
        "glove_path = \"/content/drive/MyDrive/models/lemma/glove/glove_treetagger.txt.word2vec\"\n",
        "\n",
        "# Load static word embedding models pretrained on a treetagger-lemmatized corpus\n",
        "w2v_model = StaticEmbedder(StaticEmbedder.Model.WORD2VEC, w2v_path)\n",
        "fasttext_model = StaticEmbedder(StaticEmbedder.Model.FASTTEXT, fasttext_path)\n",
        "glove_model = StaticEmbedder(StaticEmbedder.Model.GLOVE, glove_path, binary=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHOBRz1CkHXi",
        "outputId": "5583ef33-2401-4b4f-cb22-72909468fcf5"
      },
      "source": [
        "# Get some suggested collocations\n",
        "treetagger_output = [\"исследовать_V вопрос_N\", \"по_S мнение_N автор_N\"]\n",
        "\n",
        "for ngram, fixed_positions in zip(treetagger_output, [[1, 0], [1, 1, 0]]):\n",
        "  query = ngram.lower().split(\" \")\n",
        "  \n",
        "  w2v_results = w2v_model.suggest_collocations(query, fixed_positions, topn=5)\n",
        "  fasttext_results = fasttext_model.suggest_collocations(query, fixed_positions, topn=5)\n",
        "  glove_results = glove_model.suggest_collocations(query, fixed_positions, topn=25)\n",
        "  \n",
        "  print(\"Results for\", query, \":\")\n",
        "  print(\"_____w2v_____\")\n",
        "  for res in w2v_results:\n",
        "    print(res)\n",
        "  print(\"\\n_____fastText_____\")\n",
        "  for res in fasttext_results:\n",
        "    print(res)\n",
        "  print(\"\\n_____GloVe_____\")\n",
        "  for res in glove_results:\n",
        "    print(res)\n",
        "  print(\"-\"*75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for ['исследовать_v', 'вопрос_n'] :\n",
            "_____w2v_____\n",
            "('исследовать проблема', 0, 0.6838977336883545)\n",
            "('исследовать задача', 1, 0.48253941535949707)\n",
            "('исследовать спор', 2, 0.459981232881546)\n",
            "('исследовать вопрсы', 3, 0.44508951902389526)\n",
            "\n",
            "_____fastText_____\n",
            "('исследовать новопрос', 0, 0.8441401720046997)\n",
            "('исследовать вопроа', 3, 0.800765872001648)\n",
            "\n",
            "_____GloVe_____\n",
            "('исследовать итервьюера', 23, 0.5414384603500366)\n",
            "---------------------------------------------------------------------------\n",
            "Results for ['по_s', 'мнение_n', 'автор_n'] :\n",
            "_____w2v_____\n",
            "('по мнение исследователь', 0, 0.6782662272453308)\n",
            "('по мнение ученый', 2, 0.5683425664901733)\n",
            "('по мнение историк', 3, 0.443101167678833)\n",
            "\n",
            "_____fastText_____\n",
            "('по мнение исследователь', 0, 0.6990058422088623)\n",
            "('по мнение втор', 1, 0.6199074387550354)\n",
            "('по мнение ученый', 2, 0.6077357530593872)\n",
            "('по мнение пвтор', 3, 0.5964410305023193)\n",
            "\n",
            "_____GloVe_____\n",
            "('по мнение помпонио', 1, 0.7873562574386597)\n",
            "('по мнение ряженки', 2, 0.7458928227424622)\n",
            "('по мнение рсунков', 3, 0.7190617322921753)\n",
            "('по мнение экпозиций', 5, 0.6796302795410156)\n",
            "('по мнение кастаниаса', 6, 0.6711572408676147)\n",
            "('по мнение сеника', 7, 0.6687108874320984)\n",
            "('по мнение йоханом', 8, 0.660228967666626)\n",
            "('по мнение липсиц', 9, 0.6584478616714478)\n",
            "('по мнение утопизму', 14, 0.6325863003730774)\n",
            "('по мнение мытарствами', 17, 0.6175637245178223)\n",
            "('по мнение совастеевым', 18, 0.6129472255706787)\n",
            "('по мнение стихтворения', 19, 0.6094455718994141)\n",
            "('по мнение рчепорождения', 24, 0.5966158509254456)\n",
            "---------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8lkE1xKnNpg"
      },
      "source": [
        "## Getting suggested collocations from dynamic word embeddings (RoBERTa, t5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PZQDrtSnaT7"
      },
      "source": [
        "from src.dynamic_embedder import DynamicEmbedder\n",
        "\n",
        "bert_path = \"/content/drive/MyDrive/models/lemma/RuBERT_treetagger_lemma\"\n",
        "\n",
        "# Load a dynamic word embedding model trained on a treetagger-lemmatized corpus\n",
        "bert_model = DynamicEmbedder(DynamicEmbedder.Model.BERT, bert_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "277ylLfXnmjx",
        "outputId": "2d585ca6-337f-4f57-bec9-ac5dc1cb777e"
      },
      "source": [
        "# Get some suggested collocations\n",
        "treetagger_output = [\"исследовать_V <mask>_N\", \n",
        "                     \"по_S мнение_N <mask>_N\", \n",
        "                     \"рассматривать_V <mask>_N <mask>_N\"]\n",
        "\n",
        "for ngram in treetagger_output:\n",
        "  query = ngram.lower()\n",
        "  bert_results = bert_model.suggest_collocations(query, topn=5)\n",
        "  \n",
        "  print(\"Results for\", query, \":\")\n",
        "  print(\"_____RoBERTa_____\")\n",
        "  for res in bert_results:\n",
        "    print(res)\n",
        "  print(\"-\"*75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for исследовать_v <mask>_n :\n",
            "_____RoBERTa_____\n",
            "('исследовать конституция', 0)\n",
            "('исследовать законодательство', 1)\n",
            "('исследовать автореферат', 2)\n",
            "('исследовать диссертация', 3)\n",
            "('исследовать закон', 4)\n",
            "---------------------------------------------------------------------------\n",
            "Results for по_s мнение_n <mask>_n :\n",
            "_____RoBERTa_____\n",
            "('по мнение NUMarab', 0)\n",
            "('по мнение автор', 1)\n",
            "('по мнение ученый', 2)\n",
            "('по мнение эксперт', 3)\n",
            "('по мнение судья', 4)\n",
            "---------------------------------------------------------------------------\n",
            "Results for рассматривать_v <mask>_n <mask>_n :\n",
            "_____RoBERTa_____\n",
            "('рассматривать международный NUMarab', 0)\n",
            "('рассматривать международный монография', 1)\n",
            "('рассматривать международный проблема', 2)\n",
            "('рассматривать международный суд', 3)\n",
            "('рассматривать международный целесообразный', 4)\n",
            "('рассматривать содержание NUMarab', 1)\n",
            "('рассматривать содержание монография', 2)\n",
            "('рассматривать содержание проблема', 3)\n",
            "('рассматривать содержание суд', 4)\n",
            "('рассматривать содержание целесообразный', 5)\n",
            "('рассматривать проблема NUMarab', 2)\n",
            "('рассматривать проблема монография', 3)\n",
            "('рассматривать проблема проблема', 4)\n",
            "('рассматривать проблема суд', 5)\n",
            "('рассматривать проблема целесообразный', 6)\n",
            "('рассматривать этот NUMarab', 3)\n",
            "('рассматривать этот монография', 4)\n",
            "('рассматривать этот проблема', 5)\n",
            "('рассматривать этот суд', 6)\n",
            "('рассматривать этот целесообразный', 7)\n",
            "('рассматривать российский NUMarab', 4)\n",
            "('рассматривать российский монография', 5)\n",
            "('рассматривать российский проблема', 6)\n",
            "('рассматривать российский суд', 7)\n",
            "('рассматривать российский целесообразный', 8)\n",
            "---------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEkj05ksVTK_"
      },
      "source": [
        "## Getting suggested collocations & statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLWynpvsAl0G"
      },
      "source": [
        "# Run this and allow the IP on the test gcloud server \n",
        "!curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC_1VYEvVScL"
      },
      "source": [
        "from src.get_collocation_replacements import get_collocation_replacements\n",
        "from src.dynamic_embedder import DynamicEmbedder\n",
        "from src.static_embedder import LossLogger, StaticEmbedder\n",
        "\n",
        "bigrams = [l.lower() for l in [\"исследовать_V вопрос_N\", \"школа_N экономика_N\"]]\n",
        "trigrams = [l.lower() for l in [\"прийти_V к_S вывод_N\", \"по_S мнение_N автор_N\"]]\n",
        "\n",
        "w2v_path = \"/content/drive/MyDrive/models/lemma/w2v/w2v_treetagger.model\"\n",
        "bert_path = \"/content/drive/MyDrive/models/lemma/RuBERT_treetagger_lemma\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZeIa1_MOIew"
      },
      "source": [
        "bigram_results = get_collocation_replacements(collocations=bigrams, \n",
        "                                              staticModel=True, \n",
        "                                              modelType=StaticEmbedder.Model.WORD2VEC,\n",
        "                                              modelSrc=w2v_path, \n",
        "                                              binaryModel=True, # only relevant for GloVe\n",
        "                                              cossim=True,\n",
        "                                              topn=3,\n",
        "                                              replace1=True, replace2=True, replace3=False,\n",
        "                                              include_pmi=True, include_t_score=True, include_ngram_freq=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S903k8keGRTk"
      },
      "source": [
        "trigram_results = get_collocation_replacements(collocations=trigrams, \n",
        "                                              staticModel=False, \n",
        "                                              modelType=DynamicEmbedder.Model.BERT,\n",
        "                                              modelSrc=bert_path,\n",
        "                                              mask=\"<mask>\",\n",
        "                                              topn=3,\n",
        "                                              replace1=True, replace2=True, replace3=True,\n",
        "                                              include_pmi=True, include_t_score=True, include_ngram_freq=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRKFCVKXOXqz",
        "outputId": "6fe295a2-2be4-4ca1-d447-f948144e1735"
      },
      "source": [
        "def print_results(res):\n",
        "  for k,v in res.items():\n",
        "    print(f\"Results for '{k}':\")\n",
        "    for val in v:\n",
        "      print(\" \"*5, val)\n",
        "    print(\"-\"*75)\n",
        "\n",
        "print(\"*\"*5, \"BIGRAMS WITH W2V\", \"*\"*5)\n",
        "print_results(bigram_results)\n",
        "print(\"\\n\")\n",
        "print(\"*\"*5, \"TRIGRAMS WITH BERT\", \"*\"*5)\n",
        "print_results(trigram_results)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** BIGRAMS WITH W2V *****\n",
            "Results for 'исследовать_v вопрос_n':\n",
            "      {'suggested': 'анализировать вопрос', 'rank': 0, 'cosScore': 0.5687171816825867, 'numReplaced': 1, 'pmi': -1.9326116004215073, 't_score': -713.0812254264505, 'ngram_freq': 71}\n",
            "      {'suggested': 'рассматривать вопрос', 'rank': 1, 'cosScore': 0.5575243234634399, 'numReplaced': 1, 'pmi': -0.8382014019729593, 't_score': -322.48555306741184, 'ngram_freq': 2998}\n",
            "      {'suggested': 'изучить вопрос', 'rank': 2, 'cosScore': 0.553035318851471, 'numReplaced': 1, 'pmi': -1.5870879940255196, 't_score': -255.31760297908693, 'ngram_freq': 46}\n",
            "      {'suggested': 'исследовать проблема', 'rank': 0, 'cosScore': 0.6838977336883545, 'numReplaced': 1, 'pmi': -0.722491713486314, 't_score': -132.48833138166378, 'ngram_freq': 959}\n",
            "      {'suggested': 'анализировать вопрос', 'rank': 0, 'cosScore': 0.5687171816825867, 'numReplaced': 2, 'pmi': -1.9326116004215073, 't_score': -713.0812254264505, 'ngram_freq': 71}\n",
            "      {'suggested': 'рассматривать вопрос', 'rank': 1, 'cosScore': 0.5575243234634399, 'numReplaced': 2, 'pmi': -0.8382014019729593, 't_score': -322.48555306741184, 'ngram_freq': 2998}\n",
            "      {'suggested': 'изучить вопрос', 'rank': 2, 'cosScore': 0.553035318851471, 'numReplaced': 2, 'pmi': -1.5870879940255196, 't_score': -255.31760297908693, 'ngram_freq': 46}\n",
            "      {'suggested': 'исследовать проблема', 'rank': 0, 'cosScore': 0.6838977336883545, 'numReplaced': 2, 'pmi': -0.722491713486314, 't_score': -132.48833138166378, 'ngram_freq': 959}\n",
            "---------------------------------------------------------------------------\n",
            "Results for 'школа_n экономика_n':\n",
            "      {'suggested': 'учитель экономика', 'rank': 1, 'cosScore': 0.4992271065711975, 'numReplaced': 1, 'pmi': -1.9473737666819497, 't_score': -689.6667862412795, 'ngram_freq': 62}\n",
            "      {'suggested': 'учитель экономика', 'rank': 1, 'cosScore': 0.4992271065711975, 'numReplaced': 2, 'pmi': -1.9473737666819497, 't_score': -689.6667862412795, 'ngram_freq': 62}\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "***** TRIGRAMS WITH BERT *****\n",
            "Results for 'прийти_v к_s вывод_n':\n",
            "      {'suggested': 'прийти к вывод', 'rank': 0, 'numReplaced': 1, 'pmi': 0.6351189488335738, 't_score': 34.71940443123701, 'ngram_freq': 2042}\n",
            "      {'suggested': 'прийти к власть', 'rank': 2, 'numReplaced': 1, 'pmi': -1.6443524703588472, 't_score': -243.7609545514276, 'ngram_freq': 32}\n",
            "      {'suggested': 'прийти к вывод', 'rank': 0, 'numReplaced': 2, 'pmi': 0.6351189488335738, 't_score': 34.71940443123701, 'ngram_freq': 2042}\n",
            "      {'suggested': 'прийти к власть', 'rank': 2, 'numReplaced': 2, 'pmi': -1.6443524703588472, 't_score': -243.7609545514276, 'ngram_freq': 32}\n",
            "      {'suggested': 'прийти к вывод', 'rank': 0, 'numReplaced': 3, 'pmi': 0.6351189488335738, 't_score': 34.71940443123701, 'ngram_freq': 2042}\n",
            "      {'suggested': 'прийти к власть', 'rank': 2, 'numReplaced': 3, 'pmi': -1.6443524703588472, 't_score': -243.7609545514276, 'ngram_freq': 32}\n",
            "---------------------------------------------------------------------------\n",
            "Results for 'по_s мнение_n автор_n':\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 1, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 1, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по слово автор', 'rank': 2, 'numReplaced': 1, 'pmi': -0.8751056781889914, 't_score': -56.67237330170388, 'ngram_freq': 76}\n",
            "      {'suggested': 'по мнение автор', 'rank': 1, 'numReplaced': 1, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение ученый', 'rank': 2, 'numReplaced': 1, 'pmi': -0.6199384934559808, 't_score': -70.20048391336107, 'ngram_freq': 491}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 2, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 2, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по слово автор', 'rank': 2, 'numReplaced': 2, 'pmi': -0.8751056781889914, 't_score': -56.67237330170388, 'ngram_freq': 76}\n",
            "      {'suggested': 'по мнение автор', 'rank': 1, 'numReplaced': 2, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение ученый', 'rank': 2, 'numReplaced': 2, 'pmi': -0.6199384934559808, 't_score': -70.20048391336107, 'ngram_freq': 491}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 3, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение автор', 'rank': 0, 'numReplaced': 3, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по слово автор', 'rank': 2, 'numReplaced': 3, 'pmi': -0.8751056781889914, 't_score': -56.67237330170388, 'ngram_freq': 76}\n",
            "      {'suggested': 'по мнение автор', 'rank': 1, 'numReplaced': 3, 'pmi': -0.3183619055902105, 't_score': -46.52665248308975, 'ngram_freq': 1851}\n",
            "      {'suggested': 'по мнение ученый', 'rank': 2, 'numReplaced': 3, 'pmi': -0.6199384934559808, 't_score': -70.20048391336107, 'ngram_freq': 491}\n",
            "---------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}